setwd("/Users/michelle/Documents/Rutgers/Philippines/Surveys_2012")
setwd("/Users/michelle/Documents/Rutgers/Philippines/Surveys_2012")
source("code/readGPXGarmin_2014_06_07.R")
surv = read.csv('GPSSurveys2012.surveyinfo.csv')#
data = read.csv('GPSSurveys2012.clownfish.csv', stringsAsFactors=FALSE)
concatfiles = list.files(path = 'output', pattern="^track.concat.*.csv") # find all concat files#
concatfiles = concatfiles[order(concatfiles, decreasing = TRUE)] # order them by date, with newest one first#
latlong = read.csv(paste('output/', concatfiles[1], sep=''), row.names=1) # read in neweset track.concat file
# trim off lines that have no DiveNum and columns that have no header (export problem from Excel where it includes too much of the sheet)#
surv = surv[!is.na(surv$DiveNum), !grepl('^X', names(surv))]#
data = data[!is.na(data$DiveNum), !grepl('^X', names(data))]#
#
# a small amount of QA/QC#
print(paste('List of divers from DiveInfo sheet:', paste(sort(unique(surv$Divers)), collapse='; ')))#
print(paste('List of divers from Clownfish sheet:', paste(sort(unique(data$Collector)), collapse='; ')))
# prep columns in data that we will add to#
names = names(data)#
data$NumFish = NA # total number of fish (dominant species)#
data$Sizes = NA # concatenated sizes of fish (dominant species)#
data$lat = NA#
data$lon = NA#
#
# add survey name and other dive information to data#
data = merge(data, surv[,c('DiveNum', 'Date', 'Name', 'Municipality', 'GPS', 'Cover')])#
#
# remove lines that weren't observed anemones#
i = data$AnemSpp == ''#
if(any(data$Spp[i]!='')) stop('lacking anemone for a sample')#
data = data[!i,]
# combine multiple samples from the same anemone. store later samples with the first sample#
# at the moment, I make not attempt to average size, depth, or location data across multiple visits#
# THIS CODE HASN'T BEEN CHECKED YET#
dups = data$AnemID[duplicated(data$AnemID) & !is.na(data$AnemID)] # anemone IDs that appear on >1 line#
if(length(dups)>0) warning(paste('DUPLICATE ANEMONES HAVE BEEN RECORDED! CHECK CAREFULLY', paste(dups, collapse=', ')))#
#if(length(dups)>0){#
#	for(i in 1:length(dups)){#
#		inds = sort(which(data$AnemID == dups[i]))#
#		if(length(inds)<3){#
#			# get data from the second visit to the anemone#
#			newsizes = data[inds[2], c('Size1', 'Size2', 'Size3', 'Size4', 'Size5', 'Size6', 'Size7')]#
#				newsizes = as.numeric(newsizes[!(newsizes == '' | is.na(newsizes))])#
#			newcols = data[inds[2], c('Col1', 'Col2', 'Col3', 'Col4', 'Col5', 'Col6', 'Col7')]#
#				newcols = newcols[!(newcols == '' | is.na(newcols))]#
#			newids = data[inds[2], c('ID1', 'ID2', 'ID3', 'ID4', 'ID5', 'ID6', 'ID7')]#
#				newids = as.numeric(newids[!(newids == '' | is.na(newids))])#
##
#			# make sure there is data to add#
#			if(length(newsizes)>0 | length(newcols)>0 | length(newids)>0){#
#		#
#				# error checking#
#				if(length(newsizes) != length(newcols)){#
#					warning(paste('size and color vector lengths do not match, i=', i, '. Filling with NAs.'))#
#					newcols = c(newcols, rep(NA, length(newsizes)-length(newcols)))#
#				}#
#				if(length(newsizes) != length(newids)) {#
#					warning(paste('size and ID vector lengths do not match, i=', i, '. Filling with NAs.'))#
#					newids = c(newids, rep(NA, length(newsizes)-length(newids)))			#
#				}#
#					#
#				# append to the first anemone record#
#				ii = min(which(is.na(data[inds[1], c('Size1', 'Size2', 'Size3', 'Size4', 'Size5', 'Size6', 'Size7')]))) # index of first empty field on the row#
#				if(ii<7){ # only have 7 columns to add into, so can only append on simply if at least one cell is free#
#					for(j in ii:min(7,ii+length(newsizes)-1)){ # only have 7 columns, so don't go beyond#
#						ct = j - ii + 1 # index into newsizes, newcols, newids#
#						sznm = paste('Size', j, sep=''); clnm = paste('Col', j, sep=''); idnm = paste('ID', j, sep='');#
#						data[inds[1], sznm] = newsizes[ct]#
#						data[inds[1], clnm] = newcols[ct]#
#						data[inds[1], idnm] = newids[ct]#
#		#
#					}#
#					if(ii+length(newsizes)-1 > 7){ # if need to fill the 7th column with >1 individual#
#						data$Size7[inds[1]] = paste(data$Size7[inds[1]], paste(newsizes[(ct+1):length(newsizes)], collapse=','), sep=',') # paste the remaining individuals together#
#						data$Col7[inds[1]] = paste(data$Col7[inds[1]], paste(newcols[(ct+1):length(newcols)], collapse=','), sep=',')#
#						data$ID7[inds[1]] = paste(data$ID7[inds[1]], paste(newids[(ct+1):length(newids)], collapse=','), sep=',')#
#					}#
#				} else {#
#					stop('need to deal with case of 7 cols already filled')#
#				}#
#				# remove inds[2] from data#
#				data = data[-inds[2],]#
#			}			#
#		} else {#
#			stop('need to deal with case of >2 sampling times')#
#		}#
#	}#
#}
# process data for each anemone#
len = nrow(data)#
for(i in 1:len){#
	#Get date and time information for the anemone#
	date = as.character(data$Date[i])#
	datesplit = strsplit(date,"/", fixed=T)[[1]]#
	month = as.numeric(datesplit[1])#
	day = as.numeric(datesplit[2])#
	time = as.character(data$ObsTime[i])#
	timesplit = strsplit(time, ":", fixed=T)[[1]]#
		timesplit = gsub('PM|AM', '', timesplit) # strip out AM/PM#
	hour = as.numeric(timesplit[1])#
	min = as.numeric(timesplit[2])#
	sec = as.numeric(timesplit[3])#
#
	# Convert time to GMT#
	hour = hour - 8#
	if(hour <0){#
		day = day-1#
		hour = hour + 24#
	}#
	if(day == 0){ # only works because we are in January/February#
		day == 31#
		month = month-1#
	}#
#
	# Find the location records that match the date/time stamp (to nearest second)#
	latlongindex = which(latlong$month == month & latlong$day == day & latlong$hour == hour & latlong$min == min & latlong$GPS == data$GPS[i])#
	i2 = which.min(abs(latlong$sec[latlongindex] - sec))#
#
	# Calculate the lat/long for this time#
	if(length(i2)>0){#
		data$lat[i] = latlong$lat[latlongindex][i2]#
		data$lon[i] = latlong$long[latlongindex][i2]#
	}#
#
	# Add the total number of fish (only for dominant spp)#
	data$NumFish[i] = sum(c(!is.na(data$Size1[i]), !is.na(data$Size2[i]), !is.na(data$Size3[i]), !is.na(data$Size4[i]), !is.na(data$Size5[i]), !is.na(data$Size6[i])))#
	if(!is.na(data$Size7[i])){#
		num7 = length(unlist(strsplit(as.character(data$Size7[i]), split=','))) # number of fish listed in Size7#
		data$NumFish[i] = data$NumFish[i] + num7#
	}#
#
	# Add the size of fish (only for dominant spp)#
	temp = c(data$Size1[i], data$Size2[i], data$Size3[i], data$Size4[i], data$Size5[i], data$Size6[i])#
	temp = temp[!is.na(temp)]#
	temp = paste(temp, collapse=',')#
	if(!is.na(data$Size7[i])){ # parse Size7 if needed#
		temp = paste(temp, data$Size7[i], sep=',')#
	}#
	data$Sizes[i] = temp#
}
# Sort the data#
permut = order(data$DiveNum, data$ObsTime)#
data = data[permut,]#
row.names(data) = 1:nrow(data)#
#
# Examine the head and tail of the data#
head(data[,c('DiveNum', 'ObsTime', 'AnemSpp', 'Spp', 'NumFish', 'Sizes', 'lat', 'lon')])#
tail(data[,c('DiveNum', 'ObsTime', 'AnemSpp', 'Spp', 'NumFish', 'Sizes', 'lat', 'lon')])#
#
# Write out anemone data#
write.csv(data, file=paste("output/GPSSurvey.anemlatlong", Sys.Date(), ".csv", sep=""))
# Write out for QGIS (has column headers)#
data$notes = '' # for a QGIS label#
for(i in 1:nrow(data)) {#
	if(data$Spp[i] != ''){#
		if(!is.na(data$oldAnemID[i]) & !is.na(data$AnemID[i])) {#
			data$notes[i] = paste(data$AnemSpp[i], '#', data$oldAnemID[i], '/', data$AnemID[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		}#
		if(is.na(data$oldAnemID[i]) & !is.na(data$AnemID[i])) {#
			data$notes[i] = paste(data$AnemSpp[i], '#', data$AnemID[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		}#
		if(!is.na(data$oldAnemID[i]) & is.na(data$AnemID[i])) {#
			data$notes[i] = paste(data$AnemSpp[i], '#', data$oldAnemID[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		}#
		if(is.na(data$oldAnemID[i]) & is.na(data$AnemID[i])){#
			data$notes[i] = paste(data$AnemSpp[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		}#
	}#
	else data$notes[i] = as.character(data$AnemSpp[i])#
}
if(!is.na(data$oldAnemID[i]) & !is.na(data$AnemID[i])) {#
			data$notes[i] = paste(data$AnemSpp[i], '#', data$oldAnemID[i], '/', data$AnemID[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		}#
		if(is.na(data$oldAnemID[i]) & !is.na(data$AnemID[i])) {#
			data$notes[i] = paste(data$AnemSpp[i], '#', data$AnemID[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		}#
		if(!is.na(data$oldAnemID[i]) & is.na(data$AnemID[i])) {#
			data$notes[i] = paste(data$AnemSpp[i], '#', data$oldAnemID[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		}#
		if(is.na(data$oldAnemID[i]) & is.na(data$AnemID[i])){#
			data$notes[i] = paste(data$AnemSpp[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		}
Write out for QGIS (has column headers)#
data$notes = '' # for a QGIS label#
for(i in 1:nrow(data)) {#
	if(data$Spp[i] != ''){#
		# if(!is.na(data$oldAnemID[i]) & !is.na(data$AnemID[i])) {#
			# data$notes[i] = paste(data$AnemSpp[i], '#', data$oldAnemID[i], '/', data$AnemID[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		# }#
		# if(is.na(data$oldAnemID[i]) & !is.na(data$AnemID[i])) {#
			# data$notes[i] = paste(data$AnemSpp[i], '#', data$AnemID[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		# }#
		# if(!is.na(data$oldAnemID[i]) & is.na(data$AnemID[i])) {#
			# data$notes[i] = paste(data$AnemSpp[i], '#', data$oldAnemID[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		# }#
		# if(is.na(data$oldAnemID[i]) & is.na(data$AnemID[i])){#
			# data$notes[i] = paste(data$AnemSpp[i], ' w/', data$NumFish[i], ' ', data$Spp[i], sep='')#
		# }#
	}#
	else data$notes[i] = as.character(data$AnemSpp[i])#
}
out = data[,c('lat', 'lon', 'notes', 'Date', 'Name', 'Municipality')]#
write.table(out, file=paste("output/GPSSurvey.anemlatlong", Sys.Date(), " for QGIS.csv", sep=""), col.names=TRUE, sep=',', row.names=FALSE, quote=TRUE)
write.table(out, file=paste("output/GPSSurvey.anemlatlong.2012_", Sys.Date(), " for QGIS.csv", sep=""), col.names=TRUE, sep=',', row.names=FALSE, quote=TRUE)
write.csv(data, file=paste("output/GPSSurvey.anemlatlong.2012_", Sys.Date(), ".csv", sep=""))
setwd("/Users/michelle/Documents/Rutgers/Philippines/Surveys_2013")#
	anem = read.csv('output/GPSSurvey.anemlatlong.2012_2016-01-11.csv')
setwd("/Users/michelle/Documents/Rutgers/Philippines/Surveys_2012")#
	anem = read.csv('output/GPSSurvey.anemlatlong.2012_2016-01-11.csv')
# Find the largest pair of fish on each anemone#
	anem$Rank1 = NA # column of the largest individual (ID1 through ID6)#
	anem$Rank2 = NA#
#
	k = which(!is.na(anem$Size1)) # anemones with fish#
	for(i in k){#
		if(anem$Size7[i] != "" & !is.na(anem$Size7[i])){ # If I need to parse fish from the 7th column#
			temp = as.numeric(unlist(strsplit(as.character(anem$Size7[i]), split=",", fixed=T)))#
		} else {#
			temp = NA#
		}#
		j = sort(c(anem$Size1[i],anem$Size2[i],anem$Size3[i],anem$Size4[i],anem$Size5[i],temp), index.return=T, decreasing=T)$ix#
		anem$Rank1[i] = j[1]#
		anem$Rank2[i] = j[2]#
	}#
	collections = data.frame(DiveNum = character(0), Date = character(0), ObsTime = character(0), Spp = character(0), AnemID = numeric(0), Size1 = numeric(0), ID1 = character(0), Col1 = character(0), Notes=character(0), lat = numeric(0), lon = numeric(0), TopTwo = logical(0))#
	names = names(collections)#
	# add all fish that were sampled (ID is not blank)#
		# start with Size1/ID1 fish#
	k = which(anem$ID1 !="")#
	if(length(k)>0){#
		x<-subset(anem[k,], select=c(DiveNum, Date, ObsTime, Spp, AnemID, Size1, ID1, Col1, Notes, lat, lon))#
		x$TopTwo = anem$Rank1[k] == 1 | anem$Rank2[k] == 1 # is this one of the two largest on the anemone?#
		names(x)= names#
		collections = rbind(collections, x)#
	}#
	dim(collections)#
		# then Size2/ID2#
	k = which(anem$ID2 !="")#
	if(length(k)>0){#
		x<-subset(anem[k,], select=c(DiveNum, Date, ObsTime, Spp, AnemID, Size2, ID2, Col2, Notes, lat, lon))#
		x$TopTwo = anem$Rank1[k] == 2 | anem$Rank2[k] == 2#
#
		names(x)= names#
		collections = rbind(collections, x)#
	}#
	dim(collections)#
		# Size3/ID3#
	k = which(anem$ID3 !="")#
	if(length(k)>0){#
		x<-subset(anem[k,], select=c(DiveNum, Date, ObsTime, Spp, AnemID, Size3, ID3, Col3, Notes, lat, lon))#
		x$TopTwo = anem$Rank1[k] == 3 | anem$Rank2[k] == 3#
#
		names(x)= names#
		collections = rbind(collections, x)#
	}#
	dim(collections)#
		# Size4/ID4#
	k = which(anem$ID4 !="")#
	if(length(k)>0){#
		x<-subset(anem[k,], select=c(DiveNum, Date, ObsTime, Spp, AnemID, Size4, ID4, Col4, Notes, lat, lon))#
		x$TopTwo = anem$Rank1[k] == 4 | anem$Rank2[k] == 4#
#
		names(x)= names#
		collections = rbind(collections, x)#
	}#
	dim(collections)#
		# Size5/ID5#
	k = which(anem$ID5 !="")#
	if(length(k)>0){#
		x<-subset(anem[k,], select=c(DiveNum, Date, ObsTime, Spp, AnemID, Size5, ID5, Col5, Notes, lat, lon))#
		x$TopTwo = anem$Rank1[k] == 5 | anem$Rank2[k] == 5#
#
		names(x)= names#
		collections = rbind(collections, x)#
	}#
	dim(collections)#
		# Size6/ID6#
	k = which(anem$ID6 !="")#
	if(length(k)>0){#
		x<-subset(anem[k,], select=c(DiveNum, Date, ObsTime, Spp, AnemID, Size6, ID6, Col6, Notes, lat, lon))#
		x$TopTwo = anem$Rank1[k] == 6 | anem$Rank2[k] == 6#
		names(x)= names#
		collections = rbind(collections, x)#
	}#
	dim(collections)#
		# Size7/ID7: may need to be split#
	k = which(anem$ID7 !="")#
	if(length(k)>0){#
		x<-subset(anem[k,], select=c(DiveNum, Date, ObsTime, Spp, AnemID, Size7, ID7, Col7, Notes, lat, lon))#
		i = sapply(x, is.factor); x[i] = lapply(x[i], as.character) # converts factors to characters#
		x$TopTwo = NA#
		x2 = x[0,] # to hold the final values from Size7/ID7 (after disaggregating multiple entries on the same line)#
		for(i in 1:nrow(x)){ # check each row for multiple entries#
			ids = gsub(' ', '', unlist(strsplit(as.character(x$ID7[i]), split=','))) # split apart on comma and remove spaces#
			sizes = gsub(' ', '', unlist(strsplit(as.character(x$Size7[i]), split=','))) # split apart on comma#
			colors = gsub(' ', '', unlist(strsplit(as.character(x$Col7[i]), split=','))) # split apart on comma#
			for(j in 1:length(ids)){ # then check for non-NA, non-blank entries#
				if(!is.na(ids[j]) & ids[j] != '' & ids[j] != 'NA'){#
					x2 = rbind(x2, x[i,])#
					x2$ID7[nrow(x2)] = ids[j]#
					x2$Size7[nrow(x2)] = sizes[j]#
					x2$Col7[nrow(x2)] = colors[j]#
					x2$TopTwo[nrow(x2)] = anem$Rank1[k][i] == 6+j | anem$Rank2[k][i] == 6+j # not positive this is working, but not needed, I think#
				}#
			}#
		}#
		names(x2)= names#
		collections = rbind(collections, x2)#
	}#
	dim(collections)
names(collections) = c("DiveNum", "Date", "Time", "Spp", "AnemID", "Size", "ID", "Col", "Notes", "lat", "lon", "TopTwo")#
#
	collections$Notes = as.character(collections$Notes)#
	# Sort the data#
	permut = order(collections$DiveNum, collections$Time)#
	collections = collections[permut,]#
	row.names(collections) = 1:nrow(collections)#
	# Examine the data#
	collections[,c('DiveNum', 'Date', 'Time', 'lat', 'lon')]#
	# Write out collection data#
	#write.csv(collections, file=paste("output/Collections2015_", Sys.Date(), ".csv", sep=""), row.names=FALSE)#
# write.csv(collections, file=paste("output/Collections2014_", Sys.Date(), ".csv", sep=""), row.names=FALSE)#
write.csv(collections, file=paste("output/Collections2013_", Sys.Date(), ".csv", sep=""), row.names=FALSE)
# Write out collection data#
	#write.csv(collections, file=paste("output/Collections2015_", Sys.Date(), ".csv", sep=""), row.names=FALSE)#
# write.csv(collections, file=paste("output/Collections2014_", Sys.Date(), ".csv", sep=""), row.names=FALSE)#
write.csv(collections, file=paste("output/Collections2012_", Sys.Date(), ".csv", sep=""), row.names=FALSE)
setwd('~/Documents/Rutgers/Philippines/Genetics/parentage/Cervus_2016-01-06/')
dat = read.csv('DP20_edited_genepop/DP20_proposed_ID.csv', stringsAsFactors=FALSE)
nrow(dat) # 101
# add year of the sample#
dat$First.year = as.numeric(paste('20', gsub('APCL_|[0-9,A-Z]{3}L[0-9]{4}', '', dat$First.ID, perl=TRUE), sep=''))#
dat$Second.year = as.numeric(paste('20', gsub('APCL_|[0-9,A-Z]{3}L[0-9]{4}', '', dat$Second.ID, perl=TRUE), sep=''))
# add sampleid#
dat$First.SampleID_dd = gsub('L[[:digit:]]{1,}$', '', dat$First.ID)#
dat$Second.SampleID_dd = gsub('L[[:digit:]]{1,}$', '', dat$Second.ID)
setwd('~/Documents/Rutgers/Philippines/Genetics/parentage/Cervus_2016-01-06/')#
#
dat = read.csv('DP20_edited_genepop/DP20_proposed_ID.csv', stringsAsFactors=FALSE)#
nrow(dat) # 101
# add lat/lon from our Google Sheet#
require(googlesheets)#
# gs_auth(new_user = TRUE) # run this if having authorization problems#
mykey = '1Rf_dFJ5WK-vTTsIT_kHHOcFrKzQtMFtKiuXiFw1lh9Y' # for Sample_Data sheet#
gssampdat <- gs_key(mykey)#
sampledata <- gs_read(gssampdat, ws='Samples')
install.packages("googlesheets")
setwd('~/Documents/Rutgers/Philippines/Genetics/parentage/Cervus_2016-01-06/')#
#
dat = read.csv('DP20_edited_genepop/DP20_proposed_ID.csv', stringsAsFactors=FALSE)#
nrow(dat) # 101
# add lat/lon from our Google Sheet#
require(googlesheets)#
# gs_auth(new_user = TRUE) # run this if having authorization problems#
mykey = '1Rf_dFJ5WK-vTTsIT_kHHOcFrKzQtMFtKiuXiFw1lh9Y' # for Sample_Data sheet#
gssampdat <- gs_key(mykey)#
sampledata <- gs_read(gssampdat, ws='Samples')
m1 = sampledata
names(m1)
names(m1) = paste('First.', names(m1), sep='')
names(m1)
dat = merge(dat, m1, by.x='First.SampleID', by.y = 'First.Sample_ID', all.x=TRUE)#
#repeat so that there is also a second sample ID for the comparison#
m2 = sampledata#
names(m2) = paste('Second.', names(m2), sep='')#
dat = merge(dat, m2, by.x='Second.SampleID', by.y = 'Second.Sample_ID', all.x=TRUE)
names(dat)
# distance between samples#
require(fields)#
# source('greatcircle_funcs.R') # alternative, probably faster#
alldists = rdist.earth(as.matrix(dat[,c('First.Lon', 'First.Lat')]), as.matrix(dat[,c('Second.Lon', 'Second.Lat')]), miles=FALSE, R=6371) # see http://www.r-bloggers.com/great-circle-distance-calculations-in-r/ # slow because it does ALL pairwise distances, instead of just in order#
dat$distkm = diag(alldists)
install.packages(“fields”)
install.packages("fields")
# distance between samples#
require(fields)#
# source('greatcircle_funcs.R') # alternative, probably faster#
alldists = rdist.earth(as.matrix(dat[,c('First.Lon', 'First.Lat')]), as.matrix(dat[,c('Second.Lon', 'Second.Lat')]), miles=FALSE, R=6371) # see http://www.r-bloggers.com/great-circle-distance-calculations-in-r/ # slow because it does ALL pairwise distances, instead of just in order#
dat$distkm = diag(alldists)
names(dat)
dat =
()
dat=90
dat = ()
dat90
names(dat)
setwd('~/Documents/Rutgers/Philippines/Genetics/parentage/Cervus_2016-01-06/')#
#
dat = read.csv('DP20_edited_genepop/DP20_proposed_ID.csv', stringsAsFactors=FALSE)#
nrow(dat) # 101#
#
# # 	# add year of the sample#
# dat$First.year = as.numeric(paste('20', gsub('APCL_|[0-9,A-Z]{3}L[0-9]{4}', '', dat$First.ID, perl=TRUE), sep=''))#
# dat$Second.year = as.numeric(paste('20', gsub('APCL_|[0-9,A-Z]{3}L[0-9]{4}', '', dat$Second.ID, perl=TRUE), sep=''))#
	# # fix ID to always have 4-digit ligation IDs (needed for matching against Sample_Data google sheet)#
# ind = grep('L[[:digit:]]{3}$', dat$First.ID) # rows with 3-digit ligation IDs#
# dat$First.ID[ind] = gsub('L([[:digit:]]{3})$', 'L0\\1', dat$First.ID[ind])#
# ind = grep('L[[:digit:]]{3}$', dat$Second.ID)#
# dat$Second.ID[ind] = gsub('L([[:digit:]]{3})$', 'L0\\1', dat$Second.ID[ind])#
#
	# # add sampleid#
# dat$First.SampleID_dd = gsub('L[[:digit:]]{1,}$', '', dat$First.ID)#
# dat$Second.SampleID_dd = gsub('L[[:digit:]]{1,}$', '', dat$Second.ID)#
#
	# #fix sampleid from dDocent format back to Sample_Data format#
# dat$First.SampleID = paste('APCL', gsub('20', '', dat$First.year), '_', gsub('APCL_[0-9]{2}', '', dat$First.SampleID_dd, perl=TRUE), sep='')	#
# dat$Second.SampleID = paste('APCL', gsub('20', '', dat$Second.year), '_', gsub('APCL_[0-9]{2}', '', dat$Second.SampleID_dd, perl=TRUE), sep='')	#
#
	# #write out a csv of the dat up to this point - change the sample_IDs based on potential ID errors - then continue#
	# write.csv(dat, file='potential.csv')#
	# #read it back in with the changes#
	# dat = read.csv('potential.csv', stringsAsFactors=FALSE)#
	# add lat/lon from our Google Sheet#
require(googlesheets)#
# gs_auth(new_user = TRUE) # run this if having authorization problems#
mykey = '1Rf_dFJ5WK-vTTsIT_kHHOcFrKzQtMFtKiuXiFw1lh9Y' # for Sample_Data sheet#
gssampdat <- gs_key(mykey)#
sampledata <- gs_read(gssampdat, ws='Samples')#
#m1 is all of the samples sheet#
m1 = sampledata#
#add First. to the samples sheet so that it matches up with the ID sheet#
names(m1) = paste('First.', names(m1), sep='')#
#merge the ID sheet and the samples sheet#
dat = merge(dat, m1, by.x='First.SampleID', by.y = 'First.Sample_ID', all.x=TRUE)#
#repeat so that there is also a second sample ID for the comparison#
m2 = sampledata#
names(m2) = paste('Second.', names(m2), sep='')#
dat = merge(dat, m2, by.x='Second.SampleID', by.y = 'Second.Sample_ID', all.x=TRUE)
names(dat)
# distance between samples#
require(fields)#
# source('greatcircle_funcs.R') # alternative, probably faster#
alldists = rdist.earth(as.matrix(dat[,c('First.Lon.x', 'First.Lat.x')]), as.matrix(dat[,c('Second.Lon.y', 'Second.Lat.y')]), miles=FALSE, R=6371) # see http://www.r-bloggers.com/great-circle-distance-calculations-in-r/ # slow because it does ALL pairwise distances, instead of just in order#
dat$distkm = diag(alldists)
require(fields)
alldists = rdist.earth(as.matrix(dat[,c('First.Lon.x', 'First.Lat.x')]), as.matrix(dat[,c('Second.Lon.y', 'Second.Lat.y')]), miles=FALSE, R=6371)
